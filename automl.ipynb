{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Automated ML with azureml\n",
    "\n",
    "The dependencies are imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1598423888013
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from azureml.core import Dataset, Datastore, Workspace, Experiment\n",
    "# from azureml.train.automl import AutoMLConfig\n",
    "from azureml.widgets import RunDetails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "### Overview\n",
    "\n",
    "We will try to predict the rating of modified version of the **Kaggle Trip advisor dataset**.\n",
    "\n",
    "The Dataset contains a Trip Advisor hotel review text column as well as a Rating column with Ratings from 0 - 5 stars. \n",
    "\n",
    "> The Tripadvisor Hotel Review Dataset file, is derived from the publication: \n",
    ">\n",
    ">_Alam, M. H., Ryu, W.-J., Lee, S., 2016. Joint multi-grain topic senti- ment: modeling semantic aspects for online >reviews. Information Sciences 339, 206–223._ \n",
    ">\n",
    "> You can download the Dataset with the link:\n",
    "> [trip-advisor-hotel-reviews](https://www.kaggle.com/andrewmvd/trip-advisor-hotel-reviews)\n",
    "\n",
    "In the original Dataset the target **Rating** column contains the values 0* - 5*.\n",
    "\n",
    "In a modified version of the dataset we will try to predict the **norm_rating** column based on the **Review** text column as a **classification task** with:\n",
    "\n",
    "* class 0 - Negative reviews (1* & 2* rating)\n",
    "* class 1 - Neutral reviews (3* rating)\n",
    "* class 2 - Positive reviews (4* & 5* rating)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Workspace and create an Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1598423890461
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>automl_review_classifier</td><td>quick-starts-ws-134076</td><td><a href=\"https://ml.azure.com/experiments/automl_review_classifier?wsid=/subscriptions/f9d5a085-54dc-4215-9ba6-dad5d86e60a0/resourcegroups/aml-quickstarts-134076/workspaces/quick-starts-ws-134076\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Experiment(Name: automl_review_classifier,\n",
       "Workspace: quick-starts-ws-134076)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "# choose a name for experiment\n",
    "experiment_name = 'automl_review_classifier'\n",
    "\n",
    "experiment=Experiment(ws, experiment_name)\n",
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subscription key f9d5a085-54dc-4215-9ba6-dad5d86e60a0\n",
      "resource group aml-quickstarts-134076\n",
      "workspace name quick-starts-ws-134076\n"
     ]
    }
   ],
   "source": [
    "print(f\"subscription key {ws.subscription_id}\")\n",
    "print(f\"resource group {ws.resource_group}\")\n",
    "print(f\"workspace name {ws.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset and perform a train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "filepath_2_dataset = r\"hotel_reviews_featurized_roberta.csv\"\n",
    "# Read the Dataset as a pandas dataframe\n",
    "hotel_review_dataset = pd.read_csv(filepath_2_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (20491, 808)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>topic_9</th>\n",
       "      <th>...</th>\n",
       "      <th>dim_758</th>\n",
       "      <th>dim_759</th>\n",
       "      <th>dim_760</th>\n",
       "      <th>dim_761</th>\n",
       "      <th>dim_762</th>\n",
       "      <th>dim_763</th>\n",
       "      <th>dim_764</th>\n",
       "      <th>dim_765</th>\n",
       "      <th>dim_766</th>\n",
       "      <th>dim_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20491.000000</td>\n",
       "      <td>20491.000000</td>\n",
       "      <td>20491.000000</td>\n",
       "      <td>20491.000000</td>\n",
       "      <td>20491.000000</td>\n",
       "      <td>20491.000000</td>\n",
       "      <td>20491.000000</td>\n",
       "      <td>20491.000000</td>\n",
       "      <td>20491.000000</td>\n",
       "      <td>20491.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20491.000000</td>\n",
       "      <td>20491.000000</td>\n",
       "      <td>20491.000000</td>\n",
       "      <td>20491.000000</td>\n",
       "      <td>20491.000000</td>\n",
       "      <td>20491.000000</td>\n",
       "      <td>20491.000000</td>\n",
       "      <td>20491.000000</td>\n",
       "      <td>20491.000000</td>\n",
       "      <td>20491.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.001939</td>\n",
       "      <td>0.004714</td>\n",
       "      <td>0.011617</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.010981</td>\n",
       "      <td>0.003340</td>\n",
       "      <td>0.033029</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>0.019453</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027524</td>\n",
       "      <td>0.003075</td>\n",
       "      <td>-0.156707</td>\n",
       "      <td>0.102556</td>\n",
       "      <td>-0.103847</td>\n",
       "      <td>-0.022158</td>\n",
       "      <td>0.124463</td>\n",
       "      <td>-0.329340</td>\n",
       "      <td>0.020014</td>\n",
       "      <td>0.032116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.004887</td>\n",
       "      <td>0.007468</td>\n",
       "      <td>0.006196</td>\n",
       "      <td>0.003457</td>\n",
       "      <td>0.004591</td>\n",
       "      <td>0.006425</td>\n",
       "      <td>0.006819</td>\n",
       "      <td>0.008321</td>\n",
       "      <td>0.003971</td>\n",
       "      <td>0.005330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060321</td>\n",
       "      <td>0.047068</td>\n",
       "      <td>0.076493</td>\n",
       "      <td>0.050610</td>\n",
       "      <td>0.063625</td>\n",
       "      <td>0.048991</td>\n",
       "      <td>0.128676</td>\n",
       "      <td>0.105728</td>\n",
       "      <td>0.040554</td>\n",
       "      <td>0.058754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.283000</td>\n",
       "      <td>-0.307900</td>\n",
       "      <td>-0.484000</td>\n",
       "      <td>-0.252400</td>\n",
       "      <td>-0.386300</td>\n",
       "      <td>-0.254700</td>\n",
       "      <td>-0.367400</td>\n",
       "      <td>-1.016800</td>\n",
       "      <td>-0.184600</td>\n",
       "      <td>-0.216600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016300</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066900</td>\n",
       "      <td>-0.027800</td>\n",
       "      <td>-0.207700</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>-0.144750</td>\n",
       "      <td>-0.055500</td>\n",
       "      <td>0.035850</td>\n",
       "      <td>-0.399500</td>\n",
       "      <td>-0.006100</td>\n",
       "      <td>-0.006500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027700</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>-0.155100</td>\n",
       "      <td>0.103900</td>\n",
       "      <td>-0.103100</td>\n",
       "      <td>-0.023900</td>\n",
       "      <td>0.114200</td>\n",
       "      <td>-0.333100</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>0.030300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.033800</td>\n",
       "      <td>-0.104400</td>\n",
       "      <td>0.135650</td>\n",
       "      <td>-0.062200</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>0.203700</td>\n",
       "      <td>-0.264400</td>\n",
       "      <td>0.046200</td>\n",
       "      <td>0.068550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.056800</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>0.048400</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.055900</td>\n",
       "      <td>0.080800</td>\n",
       "      <td>0.056300</td>\n",
       "      <td>0.145500</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.082900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>0.231900</td>\n",
       "      <td>0.158700</td>\n",
       "      <td>0.322100</td>\n",
       "      <td>0.171700</td>\n",
       "      <td>0.243300</td>\n",
       "      <td>0.908800</td>\n",
       "      <td>0.152800</td>\n",
       "      <td>0.200600</td>\n",
       "      <td>0.370700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 807 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            topic_0       topic_1       topic_2       topic_3       topic_4  \\\n",
       "count  20491.000000  20491.000000  20491.000000  20491.000000  20491.000000   \n",
       "mean       0.001939      0.004714      0.011617      0.001034      0.001708   \n",
       "std        0.004887      0.007468      0.006196      0.003457      0.004591   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.010600      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.011500      0.000000      0.000000   \n",
       "75%        0.000000      0.010400      0.014100      0.000000      0.000000   \n",
       "max        0.056800      0.073000      0.048400      0.042000      0.055900   \n",
       "\n",
       "            topic_5       topic_6       topic_7       topic_8       topic_9  \\\n",
       "count  20491.000000  20491.000000  20491.000000  20491.000000  20491.000000   \n",
       "mean       0.010981      0.003340      0.033029      0.001340      0.019453   \n",
       "std        0.006425      0.006819      0.008321      0.003971      0.005330   \n",
       "min        0.000000      0.000000      0.014800      0.000000      0.000000   \n",
       "25%        0.010300      0.000000      0.028100      0.000000      0.016300   \n",
       "50%        0.011200      0.000000      0.030300      0.000000      0.017600   \n",
       "75%        0.014000      0.000000      0.036000      0.000000      0.022200   \n",
       "max        0.080800      0.056300      0.145500      0.033300      0.082900   \n",
       "\n",
       "       ...       dim_758       dim_759       dim_760       dim_761  \\\n",
       "count  ...  20491.000000  20491.000000  20491.000000  20491.000000   \n",
       "mean   ...     -0.027524      0.003075     -0.156707      0.102556   \n",
       "std    ...      0.060321      0.047068      0.076493      0.050610   \n",
       "min    ...     -0.283000     -0.307900     -0.484000     -0.252400   \n",
       "25%    ...     -0.066900     -0.027800     -0.207700      0.071000   \n",
       "50%    ...     -0.027700      0.002500     -0.155100      0.103900   \n",
       "75%    ...      0.011600      0.033800     -0.104400      0.135650   \n",
       "max    ...      0.262500      0.231900      0.158700      0.322100   \n",
       "\n",
       "            dim_762       dim_763       dim_764       dim_765       dim_766  \\\n",
       "count  20491.000000  20491.000000  20491.000000  20491.000000  20491.000000   \n",
       "mean      -0.103847     -0.022158      0.124463     -0.329340      0.020014   \n",
       "std        0.063625      0.048991      0.128676      0.105728      0.040554   \n",
       "min       -0.386300     -0.254700     -0.367400     -1.016800     -0.184600   \n",
       "25%       -0.144750     -0.055500      0.035850     -0.399500     -0.006100   \n",
       "50%       -0.103100     -0.023900      0.114200     -0.333100      0.019800   \n",
       "75%       -0.062200      0.008400      0.203700     -0.264400      0.046200   \n",
       "max        0.171700      0.243300      0.908800      0.152800      0.200600   \n",
       "\n",
       "            dim_767  \n",
       "count  20491.000000  \n",
       "mean       0.032116  \n",
       "std        0.058754  \n",
       "min       -0.216600  \n",
       "25%       -0.006500  \n",
       "50%        0.030300  \n",
       "75%        0.068550  \n",
       "max        0.370700  \n",
       "\n",
       "[8 rows x 807 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Dataset Shape: {hotel_review_dataset.shape}\")\n",
    "hotel_review_dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First the same train test split is performed for the Dataset to make it available to both AutoML and Hyperdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (16392, 808)\n",
      "X_test: (4099, 808)\n",
      "y_train: 16392\n",
      "y_test: 4099\n"
     ]
    }
   ],
   "source": [
    "# Get hotel review text and normalized rating\n",
    "X = hotel_review_dataset.drop(columns=['norm_rating'])\n",
    "y = list(hotel_review_dataset.norm_rating)\n",
    "X_train, X_test, y_train, y_test = train_test_split(hotel_review_dataset, y, test_size=0.2, random_state=42)\n",
    "print(f\"X_train: {X_train.shape}\\nX_test: {X_test.shape}\\ny_train: {len(y_train)}\\ny_test: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training set and test sets will be registered separately to ensure strict separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_train['norm_rating'] = y_train\n",
    "X_test['norm_rating'] = y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16392, 808)\n",
      "(4099, 808)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The AutoML train/testsets should contain just the text column and norm rating column (no feature engineering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload the different train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 4 files\n",
      "Uploading data/test_set_automl.csv\n",
      "Uploaded data/test_set_automl.csv, 1 files out of an estimated total of 4\n",
      "Uploading data/train_set_automl.csv\n",
      "Uploaded data/train_set_automl.csv, 2 files out of an estimated total of 4\n",
      "Uploading data/test_set_hyper.csv\n",
      "Uploaded data/test_set_hyper.csv, 3 files out of an estimated total of 4\n",
      "Uploading data/train_set_hyper.csv\n",
      "Uploaded data/train_set_hyper.csv, 4 files out of an estimated total of 4\n",
      "Uploaded 4 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_c3faa4c3234246f59fe09397b7fd5fbf"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_automl = X_train.loc[:, ['text', 'norm_rating']]\n",
    "X_test_automl = X_test.loc[:, ['text', 'norm_rating']]\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "# Upload the training/test data in the default datastore\n",
    "train_dataset_path_automl = \"data/train_set_automl.csv\"\n",
    "X_train_automl.to_csv(train_dataset_path_automl)\n",
    "test_dataset_path_automl = \"data/test_set_automl.csv\"\n",
    "X_test_automl.to_csv(test_dataset_path_automl)\n",
    "\n",
    "X_train_hyper = X_train.drop(columns =[\"text\"])\n",
    "X_test_hyper = X_test.drop(columns = [\"text\"])\n",
    "\n",
    "train_dataset_path = \"data/train_set_hyper.csv\"\n",
    "X_train_hyper.to_csv(train_dataset_path)\n",
    "test_dataset_path = \"data/test_set_hyper.csv\"\n",
    "X_test_hyper.to_csv(test_dataset_path)\n",
    "\n",
    "datastore = ws.get_default_datastore()\n",
    "datastore.upload(src_dir=\"data\", target_path=\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the training and test Datasets and register them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_training = Dataset.Tabular.from_delimited_files(path = [(datastore, (\"data/train_set_automl.csv\"))])\n",
    "dataset_training = dataset_training.register(workspace=ws, name=\"auto-ml-training-data\", description=\"Hotel Review AutoML Training Data\")\n",
    "\n",
    "dataset_test =  Dataset.Tabular.from_delimited_files(path = [(datastore, (\"data/test_set_automl.csv\"))])\n",
    "dataset_test = dataset_training.register(workspace=ws, name=\"auto-ml-test-data\", description=\"Hotel Review AutoML Test Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Compute Target for AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing Compute Target\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "## Define a Compute Target for AutoML\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cpu_cluster_name = \"cpu-cluster-1\"\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print(\"Found existing Compute Target\")\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size = \"Standard_D2_V2\", max_nodes=4)\n",
    "    compute_target = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML Configuration\n",
    "\n",
    "* _experiment_timeout_minutes_: was set to prevent the experiment from running for long timer periods with high cost\n",
    "* _max_concurrent_iterations_: was set to 4 since only 4 compute target nodes are available for paralle child runs\n",
    "* _primary_metric_: was set to AUC_weighted since this includes a balance between false positive and true positive rate\n",
    "* _n_cross_validations_: 5 crossvalidations were selected, since this results in a more robust mean/std estimation for each model\n",
    "\n",
    "* _enable_early_stopping_: to prevent unproductive runs which lead to no improvement and costs\n",
    "* _compute_target_: needs to be define to perform the AutoML computations\n",
    "* _task_: needs to be classification since the label column is defining separate classes\n",
    "* _training_data_: corresponds to the training set\n",
    "* _label_column_: corresponds to the target/label column defining the separate classes\n",
    "* _debug_log_: defined to enable detailed logging of automl errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.automl.automlconfig import AutoMLConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "gather": {
     "logged": 1598429217746
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "## Define key AutoML Settings\n",
    "automl_settings = {\n",
    "    \"experiment_timeout_minutes\": 20,\n",
    "    \"max_concurrent_iterations\": 4,\n",
    "    \"primary_metric\": \"accuracy\",\n",
    "    \"n_cross_validations\": 5\n",
    "}\n",
    "\n",
    "## Setup an AutoMLConfig object\n",
    "automl_config = AutoMLConfig(\n",
    "    compute_target=compute_target,\n",
    "    task=\"classification\",\n",
    "    training_data=dataset_training,\n",
    "    label_column_name=\"norm_rating\",\n",
    "    enable_early_stopping=True,\n",
    "    debug_log=\"automl_errors.log\",\n",
    "    **automl_settings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "gather": {
     "logged": 1598431107951
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on remote.\n"
     ]
    }
   ],
   "source": [
    "# The Experiment needs to be submitted in order to execute the AutoML run\n",
    "automl_run = experiment.submit(automl_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Details\n",
    "\n",
    "Write about the different models trained and their performance. Why do you think some models did better than others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16247b5a8dee47aaafb1535a5e9d1f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_AutoMLWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 's…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Running\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/automl_review_classifier/runs/AutoML_4f1c1746-a2b1-43c7-b465-6cbe3ef014af?wsid=/subscriptions/f9d5a085-54dc-4215-9ba6-dad5d86e60a0/resourcegroups/aml-quickstarts-134076/workspaces/quick-starts-ws-134076\", \"run_id\": \"AutoML_4f1c1746-a2b1-43c7-b465-6cbe3ef014af\", \"run_properties\": {\"run_id\": \"AutoML_4f1c1746-a2b1-43c7-b465-6cbe3ef014af\", \"created_utc\": \"2021-01-09T13:06:31.845905Z\", \"properties\": {\"num_iterations\": \"1000\", \"training_type\": \"TrainFull\", \"acquisition_function\": \"EI\", \"primary_metric\": \"accuracy\", \"train_split\": \"0\", \"acquisition_parameter\": \"0\", \"num_cross_validation\": \"5\", \"target\": \"cpu-cluster-1\", \"AMLSettingsJsonString\": \"{\\\"path\\\":null,\\\"name\\\":\\\"automl_review_classifier\\\",\\\"subscription_id\\\":\\\"f9d5a085-54dc-4215-9ba6-dad5d86e60a0\\\",\\\"resource_group\\\":\\\"aml-quickstarts-134076\\\",\\\"workspace_name\\\":\\\"quick-starts-ws-134076\\\",\\\"region\\\":\\\"southcentralus\\\",\\\"compute_target\\\":\\\"cpu-cluster-1\\\",\\\"spark_service\\\":null,\\\"azure_service\\\":\\\"remote\\\",\\\"many_models\\\":false,\\\"pipeline_fetch_max_batch_size\\\":1,\\\"iterations\\\":1000,\\\"primary_metric\\\":\\\"accuracy\\\",\\\"task_type\\\":\\\"classification\\\",\\\"data_script\\\":null,\\\"validation_size\\\":0.0,\\\"n_cross_validations\\\":5,\\\"y_min\\\":null,\\\"y_max\\\":null,\\\"num_classes\\\":null,\\\"featurization\\\":\\\"auto\\\",\\\"_ignore_package_version_incompatibilities\\\":false,\\\"is_timeseries\\\":false,\\\"max_cores_per_iteration\\\":1,\\\"max_concurrent_iterations\\\":4,\\\"iteration_timeout_minutes\\\":null,\\\"mem_in_mb\\\":null,\\\"enforce_time_on_windows\\\":false,\\\"experiment_timeout_minutes\\\":20,\\\"experiment_exit_score\\\":null,\\\"whitelist_models\\\":null,\\\"blacklist_algos\\\":[\\\"TensorFlowLinearClassifier\\\",\\\"TensorFlowDNN\\\"],\\\"supported_models\\\":[\\\"GradientBoosting\\\",\\\"DecisionTree\\\",\\\"LogisticRegression\\\",\\\"XGBoostClassifier\\\",\\\"SVM\\\",\\\"SGD\\\",\\\"LinearSVM\\\",\\\"BernoulliNaiveBayes\\\",\\\"RandomForest\\\",\\\"KNN\\\",\\\"ExtremeRandomTrees\\\",\\\"TensorFlowDNN\\\",\\\"AveragedPerceptronClassifier\\\",\\\"LightGBM\\\",\\\"MultinomialNaiveBayes\\\",\\\"TensorFlowLinearClassifier\\\"],\\\"auto_blacklist\\\":true,\\\"blacklist_samples_reached\\\":false,\\\"exclude_nan_labels\\\":true,\\\"verbosity\\\":20,\\\"_debug_log\\\":\\\"azureml_automl.log\\\",\\\"show_warnings\\\":false,\\\"model_explainability\\\":true,\\\"service_url\\\":null,\\\"sdk_url\\\":null,\\\"sdk_packages\\\":null,\\\"enable_onnx_compatible_models\\\":false,\\\"enable_split_onnx_featurizer_estimator_models\\\":false,\\\"vm_type\\\":\\\"STANDARD_D2_V2\\\",\\\"telemetry_verbosity\\\":20,\\\"send_telemetry\\\":true,\\\"enable_dnn\\\":false,\\\"scenario\\\":\\\"SDK-1.13.0\\\",\\\"environment_label\\\":null,\\\"force_text_dnn\\\":false,\\\"enable_feature_sweeping\\\":true,\\\"enable_early_stopping\\\":true,\\\"early_stopping_n_iters\\\":10,\\\"metrics\\\":null,\\\"enable_ensembling\\\":true,\\\"enable_stack_ensembling\\\":true,\\\"ensemble_iterations\\\":15,\\\"enable_tf\\\":false,\\\"enable_subsampling\\\":null,\\\"subsample_seed\\\":null,\\\"enable_nimbusml\\\":false,\\\"enable_streaming\\\":false,\\\"force_streaming\\\":false,\\\"track_child_runs\\\":true,\\\"allowed_private_models\\\":[],\\\"label_column_name\\\":\\\"norm_rating\\\",\\\"weight_column_name\\\":null,\\\"cv_split_column_names\\\":null,\\\"enable_local_managed\\\":false,\\\"_local_managed_run_id\\\":null,\\\"cost_mode\\\":1,\\\"lag_length\\\":0,\\\"metric_operation\\\":\\\"maximize\\\",\\\"preprocess\\\":true}\", \"DataPrepJsonString\": \"{\\\\\\\"training_data\\\\\\\": \\\\\\\"{\\\\\\\\\\\\\\\"blocks\\\\\\\\\\\\\\\": [{\\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"7053849c-a6f9-416c-ac1d-2b34fd270a0c\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Microsoft.DPrep.GetDatastoreFilesBlock\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"arguments\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"datastores\\\\\\\\\\\\\\\": [{\\\\\\\\\\\\\\\"datastoreName\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"workspaceblobstore\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"data/train_set_automl.csv\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"resourceGroup\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"aml-quickstarts-134076\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"subscription\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"f9d5a085-54dc-4215-9ba6-dad5d86e60a0\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"workspaceName\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"quick-starts-ws-134076\\\\\\\\\\\\\\\"}]}, \\\\\\\\\\\\\\\"localData\\\\\\\\\\\\\\\": {}, \\\\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\\\": true, \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": null, \\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\": null}, {\\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"8e2f9194-2894-4bac-b89c-3e8c7096021e\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Microsoft.DPrep.ParseDelimitedBlock\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"arguments\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"columnHeadersMode\\\\\\\\\\\\\\\": 3, \\\\\\\\\\\\\\\"fileEncoding\\\\\\\\\\\\\\\": 0, \\\\\\\\\\\\\\\"handleQuotedLineBreaks\\\\\\\\\\\\\\\": false, \\\\\\\\\\\\\\\"preview\\\\\\\\\\\\\\\": false, \\\\\\\\\\\\\\\"separator\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"skipRows\\\\\\\\\\\\\\\": 0, \\\\\\\\\\\\\\\"skipRowsMode\\\\\\\\\\\\\\\": 0}, \\\\\\\\\\\\\\\"localData\\\\\\\\\\\\\\\": {}, \\\\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\\\": true, \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": null, \\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\": null}, {\\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"5872be21-597e-4c33-a69b-e5b4f1cd9ba2\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Microsoft.DPrep.DropColumnsBlock\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"arguments\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"columns\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": 0, \\\\\\\\\\\\\\\"details\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"selectedColumns\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\"Path\\\\\\\\\\\\\\\"]}}}, \\\\\\\\\\\\\\\"localData\\\\\\\\\\\\\\\": {}, \\\\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\\\": true, \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": null, \\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\": null}, {\\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"2e27fbcb-13f7-4408-bd04-b8c39b595c66\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Microsoft.DPrep.SetColumnTypesBlock\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"arguments\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"columnConversion\\\\\\\\\\\\\\\": [{\\\\\\\\\\\\\\\"column\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": 2, \\\\\\\\\\\\\\\"details\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"selectedColumn\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Column1\\\\\\\\\\\\\\\"}}, \\\\\\\\\\\\\\\"typeProperty\\\\\\\\\\\\\\\": 2}, {\\\\\\\\\\\\\\\"column\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": 2, \\\\\\\\\\\\\\\"details\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"selectedColumn\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\"}}, \\\\\\\\\\\\\\\"typeProperty\\\\\\\\\\\\\\\": 0}, {\\\\\\\\\\\\\\\"column\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": 2, \\\\\\\\\\\\\\\"details\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"selectedColumn\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"norm_rating\\\\\\\\\\\\\\\"}}, \\\\\\\\\\\\\\\"typeProperty\\\\\\\\\\\\\\\": 2}]}, \\\\\\\\\\\\\\\"localData\\\\\\\\\\\\\\\": {}, \\\\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\\\": true, \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": null, \\\\\\\\\\\\\\\"annotation\\\\\\\\\\\\\\\": null}], \\\\\\\\\\\\\\\"inspectors\\\\\\\\\\\\\\\": [], \\\\\\\\\\\\\\\"meta\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"steps_added\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"4\\\\\\\\\\\\\\\"}}\\\\\\\", \\\\\\\"activities\\\\\\\": 0}\", \"EnableSubsampling\": null, \"runTemplate\": \"AutoML\", \"azureml.runsource\": \"automl\", \"display_task_type\": \"classification\", \"dependencies_versions\": \"{\\\"azureml-widgets\\\": \\\"1.19.0\\\", \\\"azureml-train\\\": \\\"1.19.0\\\", \\\"azureml-train-restclients-hyperdrive\\\": \\\"1.19.0\\\", \\\"azureml-train-core\\\": \\\"1.19.0\\\", \\\"azureml-train-automl\\\": \\\"1.19.0\\\", \\\"azureml-train-automl-runtime\\\": \\\"1.19.0\\\", \\\"azureml-train-automl-client\\\": \\\"1.19.0\\\", \\\"azureml-tensorboard\\\": \\\"1.19.0\\\", \\\"azureml-telemetry\\\": \\\"1.19.0\\\", \\\"azureml-sdk\\\": \\\"1.19.0\\\", \\\"azureml-samples\\\": \\\"0+unknown\\\", \\\"azureml-pipeline\\\": \\\"1.19.0\\\", \\\"azureml-pipeline-steps\\\": \\\"1.19.0\\\", \\\"azureml-pipeline-core\\\": \\\"1.19.0\\\", \\\"azureml-opendatasets\\\": \\\"1.19.0\\\", \\\"azureml-model-management-sdk\\\": \\\"1.0.1b6.post1\\\", \\\"azureml-mlflow\\\": \\\"1.19.0\\\", \\\"azureml-interpret\\\": \\\"1.19.0\\\", \\\"azureml-explain-model\\\": \\\"1.19.0\\\", \\\"azureml-defaults\\\": \\\"1.19.0\\\", \\\"azureml-dataset-runtime\\\": \\\"1.19.0\\\", \\\"azureml-dataprep\\\": \\\"2.6.1\\\", \\\"azureml-dataprep-rslex\\\": \\\"1.4.0\\\", \\\"azureml-dataprep-native\\\": \\\"26.0.0\\\", \\\"azureml-datadrift\\\": \\\"1.19.0\\\", \\\"azureml-core\\\": \\\"1.19.0\\\", \\\"azureml-contrib-services\\\": \\\"1.19.0\\\", \\\"azureml-contrib-server\\\": \\\"1.19.0\\\", \\\"azureml-contrib-reinforcementlearning\\\": \\\"1.19.0\\\", \\\"azureml-contrib-pipeline-steps\\\": \\\"1.19.0\\\", \\\"azureml-contrib-notebook\\\": \\\"1.19.0\\\", \\\"azureml-contrib-interpret\\\": \\\"1.19.0\\\", \\\"azureml-contrib-gbdt\\\": \\\"1.19.0\\\", \\\"azureml-contrib-fairness\\\": \\\"1.19.0\\\", \\\"azureml-contrib-dataset\\\": \\\"1.19.0\\\", \\\"azureml-cli-common\\\": \\\"1.19.0\\\", \\\"azureml-automl-runtime\\\": \\\"1.19.0\\\", \\\"azureml-automl-core\\\": \\\"1.19.0\\\", \\\"azureml-accel-models\\\": \\\"1.19.0\\\"}\", \"_aml_system_scenario_identification\": \"Remote.Parent\", \"ClientType\": \"SDK\", \"environment_cpu_name\": \"AzureML-AutoML\", \"environment_cpu_label\": \"prod\", \"environment_gpu_name\": \"AzureML-AutoML-GPU\", \"environment_gpu_label\": \"prod\", \"root_attribution\": \"automl\", \"attribution\": \"AutoML\", \"Orchestrator\": \"AutoML\", \"CancelUri\": \"https://southcentralus.experiments.azureml.net/jasmine/v1.0/subscriptions/f9d5a085-54dc-4215-9ba6-dad5d86e60a0/resourceGroups/aml-quickstarts-134076/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-134076/experimentids/cfa51c6d-3dff-4535-8538-8e8bda33d59e/cancel/AutoML_4f1c1746-a2b1-43c7-b465-6cbe3ef014af\", \"ClientSdkVersion\": \"1.19.0\", \"snapshotId\": \"00000000-0000-0000-0000-000000000000\", \"SetupRunId\": \"AutoML_4f1c1746-a2b1-43c7-b465-6cbe3ef014af_setup\", \"SetupRunContainerId\": \"dcid.AutoML_4f1c1746-a2b1-43c7-b465-6cbe3ef014af_setup\"}, \"tags\": {\"model_explain_run\": \"best_run\", \"_aml_system_azureml.automlComponent\": \"AutoML\"}, \"end_time_utc\": null, \"status\": \"Running\", \"log_files\": {}, \"log_groups\": [], \"run_duration\": \"0:01:13\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"experiment_status\", \"run_id\": \"AutoML_4f1c1746-a2b1-43c7-b465-6cbe3ef014af\", \"categories\": [0, 1], \"series\": [{\"data\": [\"DatasetEvaluation\", \"FeaturesGeneration\"]}]}, {\"name\": \"experiment_status_description\", \"run_id\": \"AutoML_4f1c1746-a2b1-43c7-b465-6cbe3ef014af\", \"categories\": [0, 1], \"series\": [{\"data\": [\"Gathering dataset statistics.\", \"Generating features for the dataset.\"]}]}], \"run_logs\": \"Your job is submitted in Azure cloud and we are monitoring to get logs...\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.19.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(automl_run ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431121770
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n"
     ]
    }
   ],
   "source": [
    "automl_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance metrics and Best Model\n",
    "\n",
    "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the performance metrics for the AutoML run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_output = automl_pipeline_run.get_pipeline_output(metrics_output_name)\n",
    "num_file_downloaded = metrics_output.download('.', show_progress=True)\n",
    "\n",
    "import json\n",
    "with open(metrics_output._path_on_datastore) as f:\n",
    "    metrics_output_result = f.read()\n",
    "    \n",
    "deserialized_metrics_output = json.loads(metrics_output_result)\n",
    "df = pd.DataFrame(deserialized_metrics_output)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the best model and the best run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = automl_pipeline_run.get_best_run_by_primary_metric()\n",
    "print(best_run.get_file_names())\n",
    "best_model = best_run.register_model(workspace=ws, model_name=\"best-automl-model\", model_path=\"outputs/automl_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431425670
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "best_run, fitted_model = automl_pipeline_run.get_output()\n",
    "print(best_run)\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test the best model\n",
    "dataset_test = Dataset.Tabular.from_delimited_files(path='https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv')\n",
    "df_test = dataset_test.to_pandas_dataframe()\n",
    "\n",
    "y_test = df_test['norm_rating']\n",
    "X_test = df_test.drop(['norm_rating'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "ypred = best_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, ypred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment\n",
    "\n",
    "In the cell below, register the model, create an inference config and deploy the model as a web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "# Create the environment\n",
    "myenv = Environment(name=\"myenv\")\n",
    "conda_dep = CondaDependencies()\n",
    "\n",
    "# Define the packages needed by the model and scripts\n",
    "conda_dep.add_conda_package(\"pandas\")\n",
    "conda_dep.add_conda_package(\"numpy\")\n",
    "conda_dep.add_conda_package(\"scikit-learn\")\n",
    "# You must list azureml-defaults as a pip dependency\n",
    "conda_dep.add_pip_package(\"azureml-defaults\")\n",
    "\n",
    "# Adds dependencies to PythonSection of myenv\n",
    "myenv.python.conda_dependencies=conda_dep\n",
    "\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\",\n",
    "                                   environment=myenv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "service_name = 'automl-review-classification'\n",
    "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
    "\n",
    "service = Model.deploy(workspace=ws,\n",
    "                       name=service_name,\n",
    "                       models=[best_model],\n",
    "                       inference_config=inference_config,\n",
    "                       deployment_config=aci_config,\n",
    "                       overwrite=True)\n",
    "service.wait_for_deployment(show_output=True)\n",
    "print(\"scoring URI: \" + service.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598431657736
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "TODO: In the cell below, send a request to the web service you deployed to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598432707604
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "# Get a token to authenticate to the compute instance from remote\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()\n",
    "\n",
    "# Create and submit a request using the auth header\n",
    "headers = auth_header\n",
    "# Add content type header\n",
    "headers.update({'Content-Type':'application/json'})\n",
    "\n",
    "# Sample data to send to the service\n",
    "test_sample = json.dumps({'data': [\n",
    "    [1,2,3,4,5,6,7,8,9,10],\n",
    "    [10,9,8,7,6,5,4,3,2,1]\n",
    "]})\n",
    "test_sample = bytes(test_sample, encoding = 'utf8')\n",
    "\n",
    "# Replace with the URL for your compute instance, as determined from the previous section\n",
    "service_url = service.endpoint\n",
    "# for a compute instance, the url would be https://vm-name-6789.northcentralus.instances.azureml.net/score\n",
    "response = requests.post(service_url, test_sample, headers=headers)\n",
    "print(\"prediction:\", response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598432765711
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "TODO: In the cell below, print the logs of the web service and delete the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "print(local_service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mport os\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "# SENTIMENT\n",
    "POSITIVE = \"POSITIVE\"\n",
    "NEGATIVE = \"NEGATIVE\"\n",
    "NEUTRAL = \"NEUTRAL\"\n",
    "SENTIMENT_THRESHOLDS = (0.4, 0.7)\n",
    "SEQUENCE_LENGTH = 300\n",
    "\n",
    "# Called when the deployed service starts\n",
    "def init():\n",
    "    global model\n",
    "    global tokenizer\n",
    "    global encoder\n",
    "    global w2v_model\n",
    "\n",
    "    # Get the path where the deployed model can be found.\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), './models')\n",
    "    # load models\n",
    "    model = load_model(model_path + '/model.h5')\n",
    "    w2v_model = Word2Vec.load(model_path + '/model.w2v')\n",
    "\n",
    "    with open(model_path + '/tokenizer.pkl','rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "\n",
    "    with open(model_path + '/encoder.pkl','rb') as handle:\n",
    "        encoder = pickle.load(handle)\n",
    "\n",
    "# Handle requests to the service\n",
    "def run(data):\n",
    "    try:\n",
    "        # Pick out the text property of the JSON request.\n",
    "        # This expects a request in the form of {\"text\": \"some text to score for sentiment\"}\n",
    "        data = json.loads(data)\n",
    "        prediction = predict(data['text'])\n",
    "        #Return prediction\n",
    "        return prediction\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        return error\n",
    "\n",
    "# Determine sentiment from score\n",
    "def decode_sentiment(score, include_neutral=True):\n",
    "    if include_neutral:\n",
    "        label = NEUTRAL\n",
    "        if score <= SENTIMENT_THRESHOLDS[0]:\n",
    "            label = NEGATIVE\n",
    "        elif score >= SENTIMENT_THRESHOLDS[1]:\n",
    "            label = POSITIVE\n",
    "        return label\n",
    "    else:\n",
    "        return NEGATIVE if score < 0.5 else POSITIVE\n",
    "\n",
    "# Predict sentiment using the model\n",
    "def predict(text, include_neutral=True):\n",
    "    start_at = time.time()\n",
    "    # Tokenize text\n",
    "    x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=SEQUENCE_LENGTH)\n",
    "    # Predict\n",
    "    score = model.predict([x_test])[0]\n",
    "    # Decode sentiment\n",
    "    label = decode_sentiment(score, include_neutral=include_neutral)\n",
    "\n",
    "    return {\"label\": label, \"score\": float(score),\n",
    "       \"elapsed_time\": time.time()-start_at}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
